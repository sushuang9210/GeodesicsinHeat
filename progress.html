

    <section class="main-content">
      <h2>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Project Checkpoint</b></h2>

<h3> Environment Setup (April 3 - 5) </h3>

<p> As outlined in our proposal, our plan is to first have the odometry (tracking) and loop closure parts of the system full working and parallelized before we descent onto generating depth maps for a monocular camera. To obtain depth maps to work with in the beginning, we use the Kinect for Xbox 360, which generates RGB and depth images. </p>

<p> We borrowed Kayvon's Jetson Tegra K1 development kit for the project. We access the Tegra K1 by connecting it to the internet via Ethernet, and ssh-ing into it from a machine connected to the same LAN. The Tegra K1 had been flashed with the Linux for Tegra (L4T) release R19. So we installed the following software on the Tegra: </p>
<ul>
	<li> CUDA Toolkit 6.0 </li>
	<li> OpenCV 2.4.9 </li>
	<li> OpenKinect's libfreenect library </li>
</ul>
<p> We managed to get libfreenect working with the Kinect, and subsequently with OpenCV as well. We now have RGB and depth images streaming from the Kinect using OpenCV code. The next steps will be to explore OpenCV's CUDA packages to avoid implementing any redundant functions. At any rate, we will look to improve the OpenCV implementations. We will also try to chart out a pseudo-code for the tracking algorithm, and begin its basic implementation soon. </p>


<h3> Testing the Benchmark Code (April 9 - 11) </h3>

<p> OpenCVâ€™s package includes a dense RGB-D odometry example which we are using as a reference and as a benchmark. We have tested their algorithm against a few sample images. </p>

<h3> Implementation (April 13 - Present) </h3>
<ul>
	<li> We plan to implement RGB-D odometry on the GPU and then on the CPU. We spent 3 days, between April 9th and 11th, breaking down different parts of the serial algorithm, to understand the algorithm as well as to plan the potential parallelism in the algorithm. This was especially important while using OpenCV because it has in-built GPU specific data structures and functions. </li>
	<li> We began with Cuda implementation of RGB-D odometry. We have a preliminary algorithm up and running. We plan to work on optimizing the algorithm further, to get real-time execution. We will have some priliminary results up on the website within the next few days </li>
</ul>

<h3> Revised Project Goals and Parallelism Competition (Present - May 11) </h3>
<ul>
	<li> We believe that we will be able to produce real-time CPU and GPU implementation of Visual Odometry. Once we have this working, we will move on to the next phase, where we will be working on Loop closure. </li>
	<li> We intend to show a demo of real time camera tracking on CPU and GPU. We also intend to show a comparison between pure CPU and GPU based on energy consumption </li>
</ul>



      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/uprasad/CubeRover">CubeRover</a> is maintained by <a href="https://github.com/uprasad">uprasad</a> & <a href="https://github.com/nikithashr">nikithashr</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

  
</section>
